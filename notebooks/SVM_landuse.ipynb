{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Use SVM to seperate the predict land use type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pl.style.use('fivethirtyeight')\n",
    "pl.rcParams['figure.figsize'] = (16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ID', 'GPS_DATETIMESTAMP', 'GPS_LAT', 'GPS_LON', 'GPS_Speed',\\\n",
    "           'GPS_Alt', 'GPS_Sats', 'GPS_Fix', 'GPS_Quality', 'AMB_Temp', \\\n",
    "           'AMB_Humd', 'AMB_Lux', 'AMB_Snd', 'AMB_SndMin', 'AMB_SndMax',\\\n",
    "           'AMB_SndMea', 'RDQ_AcX', 'RDQ_AcXMin', 'RDQ_AcXMax', 'RDQ_AcXMea',\\\n",
    "           'RDQ_AcY', 'RDQ_AcYMin', 'RDQ_AcYMax', 'RDQ_AcYMea', 'RDQ_AcZ',\\\n",
    "           'RDQ_AcZMin', 'RDQ_AcZMax', 'RDQ_AcZMea', 'sensor', 'timestamp',\\\n",
    "           'hourOfDay', 'minuteOfDay', 'minuteStretched', 'LU05_DESC',\\\n",
    "           'LUCODE', 'merge_key', 'day', 'sensor_num', 'sensor_day',\\\n",
    "           'keep_SndMean', 'is_loud', 'is_dark', 'acel', 'bumpflag', 'latlon_match']\n",
    "predictors = [columns.index('is_loud'), columns.index('is_dark'), columns.index('bumpflag')]\n",
    "\n",
    "x_train = np.load('../data/x_train.npy')\n",
    "y_train = np.load('../data/y_train.npy')\n",
    "x_test = np.load('../data/x_test.npy')\n",
    "y_test = np.load('../data/y_test.npy')\n",
    "x_valid = np.load('../data/x_valid.npy')\n",
    "y_valid = np.load('../data/y_valid.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_predictors_train = x_train[:,predictors]\n",
    "x_predictors_test = x_test[:,predictors]\n",
    "x_predictors_valid = x_valid[:,predictors]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using flags\n",
    "    - is_loud\n",
    "    - is_dark\n",
    "    - is_bump\n",
    "\n",
    "### Training over several types of kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we successfully(OS) predict the 58.830541631 percent of data using a linear kernel\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(svm.SVC(kernel='linear', C=1.0, class_weight='balanced'))\n",
    "clf.fit(x_predictors_train, y_train)\n",
    "\n",
    "right=1.0*(clf.predict(x_predictors_test)==np.asarray(y_test)).sum()/len(y_test)\n",
    "\n",
    "print \"we successfully(OS) predict the {} percent of data using a linear kernel\".format((right)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we successfully(OS) predict the 58.530994009 percent of data using a rbf kernel\n"
     ]
    }
   ],
   "source": [
    "rbf_clf = OneVsRestClassifier(svm.SVC(kernel='rbf', C=1.0, class_weight='balanced'))\n",
    "rbf_clf.fit(x_predictors_train, y_train)\n",
    "\n",
    "right=1.0*(rbf_clf.predict(x_predictors_test)==np.asarray(y_test)).sum()/len(y_test)\n",
    "\n",
    "print \"we successfully(OS) predict the {} percent of data using a rbf kernel\".format((right)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we successfully(OS) predict the 53.1116273383 percent of data using a poly kernel\n"
     ]
    }
   ],
   "source": [
    "poly_clf = OneVsRestClassifier(svm.SVC(kernel='poly', C=1.0, class_weight='balanced'))\n",
    "poly_clf.fit(x_predictors_train, y_train)\n",
    "\n",
    "right=1.0*(poly_clf.predict(x_predictors_test)==np.asarray(y_test)).sum()/len(y_test)\n",
    "\n",
    "print \"we successfully(OS) predict the {} percent of data using a poly kernel\".format((right)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.system('say \"Completed prediction for flags\"');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using standard normal variables\n",
    "    - Sound\n",
    "    - Light\n",
    "    - Z axis acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transforming sound values to standard normal\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "std_norm_sound_train = std_scaler.fit_transform(x_train[:,columns.index('AMB_SndMea')])\n",
    "std_norm_sound_valid = std_scaler.fit_transform(x_valid[:,columns.index('AMB_SndMea')])\n",
    "std_norm_sound_test = std_scaler.fit_transform(x_test[:,columns.index('AMB_SndMea')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transforming light values to standard normal\n",
    "std_norm_light_train = std_scaler.fit_transform(x_train[:,columns.index('AMB_Lux')])\n",
    "std_norm_light_valid = std_scaler.fit_transform(x_valid[:,columns.index('AMB_Lux')])\n",
    "std_norm_light_test = std_scaler.fit_transform(x_test[:,columns.index('AMB_Lux')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transforming z axis accelerometer values to standard normal\n",
    "std_norm_bump_train = std_scaler.fit_transform(x_train[:,columns.index('RDQ_AcZMea')])\n",
    "std_norm_bump_valid = std_scaler.fit_transform(x_valid[:,columns.index('RDQ_AcZMea')])\n",
    "std_norm_bump_test = std_scaler.fit_transform(x_test[:,columns.index('RDQ_AcZMea')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping sound flag (1st column) \n",
    "x_sound_predictors_train = x_predictors_train[:,1:]\n",
    "x_sound_predictors_test = x_predictors_test[:,1:]\n",
    "x_sound_predictors_valid = x_predictors_valid[:,1:]\n",
    "\n",
    "# Adding sound std normal values\n",
    "x_sound_predictors_train = np.insert(x_sound_predictors_train, 0,std_norm_sound_train, axis = 1)\n",
    "x_sound_predictors_test = np.insert(x_sound_predictors_test, 0,std_norm_sound_test, axis = 1)\n",
    "x_sound_predictors_valid = np.insert(x_sound_predictors_valid, 0,std_norm_sound_valid, axis = 1)\n",
    "#TODO : Include accelerator values on all axes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training over a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test train and validation with std norm variables instead of flag\n",
    "\n",
    "x_std_predictors_train = np.array([std_norm_sound_train, std_norm_bump_train, std_norm_light_train]).T\n",
    "x_std_predictors_test = np.array([std_norm_sound_test, std_norm_bump_test, std_norm_light_test]).T\n",
    "x_std_predictors_valid = np.array([std_norm_sound_valid, std_norm_bump_valid, std_norm_light_valid]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we successfully(OS) predict the 52.2129844724 percent of data using a linear kernel\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(svm.SVC(kernel='linear', C=1.0, class_weight='balanced'))\n",
    "clf.fit(x_std_predictors_train, y_train)\n",
    "\n",
    "right=1.0*(clf.predict(x_std_predictors_test)==np.asarray(y_test)).sum()/len(y_test)\n",
    "\n",
    "print \"we successfully(OS) predict the {} percent of data using a linear kernel\".format((right)*100)\n",
    "\n",
    "os.system('say \"Completed classification using standard normal variables\"');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntuned_parameters = [{\\'kernel\\': [\\'rbf\\'], \\'gamma\\': [1e-3, 1e-4],\\n                     \\'C\\': [1, 10, 100, 1000]},\\n                    {\\'kernel\\': [\\'linear\\'], \\'C\\': [1, 10, 100, 1000]}]\\n\\nvalidate_clf = GridSearchCV(svm.SVC(C=1), tuned_parameters, cv=5,\\n                       scoring=\\'%s_weighted\\' % \\'recall\\')\\nvalidate_clf.fit(x_predictors_train, y_train)\\n\\nvalidate_clf.best_params_\\n\\nC = np.linspace(-5,50,10)\\nC=[math.exp(i) for i in C]\\nOS_validation=[]\\nfor c in C:\\n    clf = svm.SVC(kernel=\\'linear\\',C=c) \\n    clf.fit(x_predictors_train, y_train)\\n    right=1.0*(clf.predict(x_predictors_valid)==np.asarray(y_valid)).sum()/len(y_valid)\\n    OS_validation.append(right)\\n    \\ntemp=pd.DataFrame([C,OS_validation]).T\\nind=len(temp.loc[temp.iloc[:,1]==temp.iloc[:,1].max()])/2 \\nC_opt=temp.loc[temp.iloc[:,1]==temp.iloc[:,1].max()].iloc[ind,0]\\n\\n\\nC=[math.log(y,10) for y in C]# for a better graph\\npylab.plot(C,OS_validation,\\'b\\',)\\npylab.legend(loc=\\'upper right\\')\\npylab.ylabel(\\'Accuracy\\')\\npylab.xlabel(\\'log(C)\\')\\npylab.show()\\n\\nprint(\"The optimal C we found is:{}\".format(C_opt)) \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "validate_clf = GridSearchCV(svm.SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_weighted' % 'recall')\n",
    "validate_clf.fit(x_predictors_train, y_train)\n",
    "\n",
    "validate_clf.best_params_\n",
    "\n",
    "C = np.linspace(-5,50,10)\n",
    "C=[math.exp(i) for i in C]\n",
    "OS_validation=[]\n",
    "for c in C:\n",
    "    clf = svm.SVC(kernel='linear',C=c) \n",
    "    clf.fit(x_predictors_train, y_train)\n",
    "    right=1.0*(clf.predict(x_predictors_valid)==np.asarray(y_valid)).sum()/len(y_valid)\n",
    "    OS_validation.append(right)\n",
    "    \n",
    "temp=pd.DataFrame([C,OS_validation]).T\n",
    "ind=len(temp.loc[temp.iloc[:,1]==temp.iloc[:,1].max()])/2 \n",
    "C_opt=temp.loc[temp.iloc[:,1]==temp.iloc[:,1].max()].iloc[ind,0]\n",
    "\n",
    "\n",
    "C=[math.log(y,10) for y in C]# for a better graph\n",
    "pylab.plot(C,OS_validation,'b',)\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.ylabel('Accuracy')\n",
    "pylab.xlabel('log(C)')\n",
    "pylab.show()\n",
    "\n",
    "print(\"The optimal C we found is:{}\".format(C_opt)) \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
